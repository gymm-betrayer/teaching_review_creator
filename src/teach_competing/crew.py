import os
import uuid
import json
from pydantic import BaseModel
import re
from crewai import Agent, Crew, Process, Task, LLM
from crewai.project import CrewBase, agent, crew, task
from crewai.agents.agent_builder.base_agent import BaseAgent
from typing import List
from dotenv import load_dotenv
import pdfplumber
from pathlib import Path
from openai import OpenAI
from uuid import uuid4
from typing import List, Dict, Any, Optional
from crewai.tools import BaseTool
import chromadb
from chromadb import PersistentClient
from chromadb.utils import embedding_functions
from chromadb.errors import NotFoundError


# If you want to run a snippet of code before or after the crew starts,
# you can use the @before_kickoff and @after_kickoff decorators
# https://docs.crewai.com/concepts/crews#example-crew-class-with-decorators

load_dotenv()

dashscope_client = OpenAI(api_key=os.getenv("DASHSCOPE_API_KEY"),
                          base_url=os.getenv("DASHSCOPE_URL"))

def extract_text_from_pdf(pdf_path: str) -> str:
    """ä»å•ä¸ª PDF æ–‡ä»¶æå–çº¯æ–‡æœ¬"""
    try:
        import PyPDF2
        with open(pdf_path, "rb") as f:
            reader = PyPDF2.PdfReader(f)
            text = ""
            for page in reader.pages:
                text += page.extract_text() or ""
        return text
    except Exception as e:
        print(f"âš ï¸ æ— æ³•è¯»å– {pdf_path}: {e}")
        return ""

def load_all_pdfs_from_directory(directory: str) -> List[Dict[str, str]]:
    """
    åŠ è½½ç›®å½•ä¸‹æ‰€æœ‰ PDFï¼Œè¿”å› [{'filename': ..., 'text': ...}, ...]
    """
    directory = Path(directory)
    if not directory.exists():
        raise FileNotFoundError(f"ç›®å½•ä¸å­˜åœ¨: {directory}")

    pdf_files = list(directory.glob("*.pdf"))
    if not pdf_files:
        raise ValueError(f"ç›®å½• {directory} ä¸­æ²¡æœ‰æ‰¾åˆ° .pdf æ–‡ä»¶")

    documents = []
    for pdf_file in pdf_files:
        print(f"ğŸ“„ æ­£åœ¨è¯»å–: {pdf_file.name}")
        text = extract_text_from_pdf(str(pdf_file))
        if text.strip():
            documents.append({
                "filename": pdf_file.stem,  # ä¸å¸¦ .pdf åç¼€
                "text": text
            })
        else:
            print(f"âš ï¸ è·³è¿‡ç©ºæ–‡ä»¶: {pdf_file.name}")

    return documents

def split_pdf_into_chapters(text: str) -> List[Dict[str, str]]:
    """
    å°†å­¦æœ¯ PDF æ–‡æœ¬æŒ‰ç« èŠ‚åˆ‡åˆ†ï¼Œæ’é™¤å‚è€ƒæ–‡çŒ®åŠä¹‹åå†…å®¹
    è¿”å›ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªç« èŠ‚å«ï¼štitle, content, level (1/2/3)
    """
    # Step 1: æˆªæ–­â€œå‚è€ƒæ–‡çŒ®â€åŠä¹‹åå†…å®¹
    ref_match = re.search(r'^\s*å‚è€ƒæ–‡çŒ®\s*$', text, re.MULTILINE | re.IGNORECASE)
    if ref_match:
        text = text[:ref_match.start()]

    # Step 2: æŒ‰è¡Œåˆ†å‰²
    lines = text.split('\n')

    # Step 3: å®šä¹‰æ ‡é¢˜æ­£åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
    patterns = [
        (1, re.compile(r'^\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€)\s*(.+)$')),  # ä¸€ã€XXX
        (2, re.compile(r'^\s*ï¼ˆ([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)ï¼‰\s*(.+)$')),  # ï¼ˆä¸€ï¼‰XXX
        (3, re.compile(r'^\s*(\d+)\.\s+(.+)$')),  # 1. XXX
    ]

    chapters = []
    current = None

    for line in lines:
        line = line.rstrip()
        if not line:
            continue

        # æ£€æŸ¥æ˜¯å¦ä¸ºæ ‡é¢˜
        is_title = False
        for level, pattern in patterns:
            match = pattern.match(line)
            if match:
                # ä¿å­˜ä¸Šä¸€ç« 
                if current:
                    chapters.append(current)

                # æ–°å»ºç« èŠ‚
                if level == 1:
                    title = match.group(0).strip()
                elif level == 2:
                    title = f"ï¼ˆ{match.group(1)}ï¼‰{match.group(2)}"
                else:  # level == 3
                    title = f"{match.group(1)}. {match.group(2)}"

                current = {
                    "title": title,
                    "content": "",
                    "level": level
                }
                is_title = True
                break

        if not is_title:
            if current is None:
                # å¼€å¤´æ®µè½ï¼ˆæ‘˜è¦åã€ç¬¬ä¸€ç« å‰ï¼‰â†’ å½’å…¥è™šæ‹Ÿâ€œå¼•è¨€â€
                if not chapters and any(kw in line for kw in ["ChatGPT", "äººå·¥æ™ºèƒ½æ—¶ä»£", "æœ¬æ–‡å°†"]):
                    current = {
                        "title": "å¼•è¨€",
                        "content": line + "\n",
                        "level": 1
                    }
                else:
                    # å¿½ç•¥å°é¢ã€ä½œè€…ã€æ‘˜è¦ç­‰ï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
                    continue
            else:
                current["content"] += line + "\n"

    # æ·»åŠ æœ€åä¸€ç« 
    if current:
        chapters.append(current)

    # åˆå¹¶â€œå¼•è¨€â€åˆ°ç¬¬ä¸€ç« ï¼ˆå¯é€‰ï¼‰
    if len(chapters) >= 2 and chapters[0]["title"] == "å¼•è¨€":
        intro = chapters.pop(0)
        chapters[0]["content"] = intro["content"] + chapters[0]["content"]
        chapters[0]["title"] = f"{chapters[0]['title']}ï¼ˆå«å¼•è¨€ï¼‰"

    return chapters


def ingest_pdfs_to_chromadb(
    pdf_dir: str,
    collection_name: str,
    persist_directory: str = "./chroma_db",
    model_name: str = "BAAI/bge-small-zh-v1.5"
) -> chromadb.Collection:
    """
    ä»æŒ‡å®šç›®å½•è¯»å–æ‰€æœ‰ PDFï¼Œè‡ªåŠ¨åˆ‡åˆ†ç« èŠ‚ï¼Œå¹¶å­˜å…¥ ChromaDBã€‚
    å¦‚æœé›†åˆå·²å­˜åœ¨ï¼Œåˆ™åŠ è½½å¹¶å¤ç”¨ï¼ˆéœ€é‡æ–°æä¾› embedding functionï¼‰ã€‚
    """
    pdf_dir = Path(pdf_dir)
    if not pdf_dir.exists():
        raise FileNotFoundError(f"PDF ç›®å½•ä¸å­˜åœ¨: {pdf_dir}")

    pdf_files = list(pdf_dir.glob("*.pdf"))
    if not pdf_files:
        raise ValueError(f"ç›®å½• {pdf_dir} ä¸­æ²¡æœ‰ .pdf æ–‡ä»¶")

    print(f"ğŸ“ æ‰¾åˆ° {len(pdf_files)} ä¸ª PDF æ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...")

    # åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯
    client = PersistentClient(path=persist_directory)

    # åˆå§‹åŒ– embedding functionï¼ˆå¿…é¡»åœ¨ create å’Œ get æ—¶éƒ½ä½¿ç”¨ï¼‰
    embedding_func = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name=model_name,
        device="cpu"
    )

    # å°è¯•è·å–ç°æœ‰é›†åˆï¼›å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»º
    try:
        collection = client.get_collection(
            name=collection_name,
            embedding_function=embedding_func  # â† å…³é”®ï¼šå¿…é¡»ä¼ ï¼
        )
        print(f"ğŸ“‚ åŠ è½½ç°æœ‰é›†åˆ: {collection_name}")
    except NotFoundError:
        print(f"ğŸ†• é›†åˆ {collection_name} ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º...")
        collection = client.create_collection(
            name=collection_name,
            embedding_function=embedding_func,
            metadata={"hnsw:space": "cosine"}
        )

    # æ‰¹é‡å¤„ç† PDF
    all_documents = []
    all_metadatas = []
    all_ids = []
    global_idx = 0

    for pdf_file in pdf_files:
        print(f"ğŸ“„ å¤„ç†: {pdf_file.name}")
        raw_text = extract_text_from_pdf(str(pdf_file))
        if not raw_text.strip():
            print(f"   âš ï¸ è·³è¿‡ç©ºæ–‡ä»¶")
            continue

        chapters = split_pdf_into_chapters(raw_text)
        source_name = pdf_file.stem  # ä¸å¸¦ .pdf åç¼€

        for chap in chapters:
            content = chap["content"].strip()
            if len(content) < 50:  # è¿‡æ»¤å¤ªçŸ­çš„ç‰‡æ®µ
                continue

            doc_id = f"{collection_name}_{global_idx:06d}"
            all_documents.append(content)
            all_metadatas.append({
                "title": chap["title"],
                "level": chap["level"],
                "source": source_name,
                "chunk_type": "chapter" if chap["level"] == 1 else "subsection",
                "index": global_idx
            })
            all_ids.append(doc_id)
            global_idx += 1

    if not all_documents:
        raise ValueError("æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆç« èŠ‚å†…å®¹")

    # æ‰¹é‡æ·»åŠ åˆ°é›†åˆ
    collection.add(
        documents=all_documents,
        metadatas=all_metadatas,
        ids=all_ids
    )

    print(f"âœ… æˆåŠŸå…¥åº“ {len(all_documents)} ä¸ªç« èŠ‚ï¼ˆæ¥è‡ª {len(pdf_files)} ä¸ª PDFï¼‰")
    print(f"ğŸ§  ä½¿ç”¨æ¨¡å‹: {model_name}")
    print(f"ğŸ’¾ å­˜å‚¨è·¯å¾„: {persist_directory}")
    return collection


def retrieve_from_chromadb(
        query: str,
        collection_name: str,
        n_results: int = 3,
        where_filter: Optional[Dict[str, Any]] = None,
        persist_directory: str = "./chroma_db"
) -> List[Dict[str, Any]]:
    """
    ä» ChromaDB æ£€ç´¢ç›¸å…³ç« èŠ‚ï¼Œå¹¶è¿”å›å†…å®¹ + level ç­‰å…ƒæ•°æ®

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
        collection_name: é›†åˆåç§°
        n_results: è¿”å›ç»“æœæ•°é‡
        where_filter: ChromaDB è¿‡æ»¤æ¡ä»¶ï¼Œå¦‚ {"level": 1}
        persist_directory: æ•°æ®åº“å­˜å‚¨è·¯å¾„

    Returns:
        List of dict with keys: content, level, title, source, score
    """
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    client = chromadb.PersistentClient(path=persist_directory)
    collection = client.get_collection(collection_name)

    # æ‰§è¡ŒæŸ¥è¯¢ï¼ˆè‡ªåŠ¨ embeddingï¼‰
    results = collection.query(
        query_texts=[query],
        n_results=n_results,
        where=where_filter,
        include=["documents", "metadatas", "distances"]
    )

    # è§£æç»“æœ
    retrieved = []
    for i in range(len(results["ids"][0])):
        doc = results["documents"][0][i]
        meta = results["metadatas"][0][i]
        distance = results["distances"][0][i]

        # è½¬æ¢ distance ä¸º similarity scoreï¼ˆChroma é»˜è®¤ç”¨ L2 æˆ– cosine è·ç¦»ï¼‰
        # å¦‚æœä½¿ç”¨ cosine è·ç¦»ï¼šsimilarity = 1 - distance
        # å¦‚æœä½¿ç”¨å†…ç§¯ï¼ˆIPï¼‰ï¼šéœ€ç‰¹æ®Šå¤„ç†ï¼Œä½†æˆ‘ä»¬ç”¨çš„æ˜¯ cosineï¼ˆbge é»˜è®¤ï¼‰
        score = 1.0 - distance

        retrieved.append({
            "content": doc,
            "level": meta["level"],  # int: 1, 2, 3...
            "title": meta["title"],  # str
            "source": meta["source"],  # str
            "chunk_type": meta["chunk_type"],  # str
            "score": round(score, 4)  # float, 0~1
        })

    # æŒ‰ score é™åºï¼ˆè™½ç„¶ Chroma å·²æ’åºï¼Œä½†ä¿é™©èµ·è§ï¼‰
    retrieved.sort(key=lambda x: x["score"], reverse=True)

    return retrieved


class ChromaDBSearchTool(BaseTool):
    name: str = "ChromaDB è¯­ä¹‰æ£€ç´¢å·¥å…·"
    description: str = (
        "æ ¹æ®è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œä»æœ¬åœ° ChromaDB å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢ç›¸å…³å­¦æœ¯ç« èŠ‚å†…å®¹ã€‚"
        "è¿”å›ç»“æœåŒ…å«æ¥æºæ–‡ä»¶ã€ç« èŠ‚æ ‡é¢˜ã€å±‚çº§å’Œå…·ä½“å†…å®¹ï¼Œé€‚ç”¨äºå›ç­”æ•™è‚²ã€æ”¿ç­–ç±»é—®é¢˜ã€‚"
    )

    # å¯é…ç½®å‚æ•°ï¼ˆé€šè¿‡å®ä¾‹åŒ–æ—¶ä¼ å…¥ï¼‰
    collection_name: str = "ai_research"
    persist_directory: str = "./chroma_db"
    n_results: int = 4

    def _run(self, query: str, level_filter: Optional[int] = None) -> str:
        """
        æ‰§è¡Œæ£€ç´¢

        Args:
            query (str): ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€é—®é¢˜
            level_filter (int, optional): ä»…æ£€ç´¢æŒ‡å®šå±‚çº§ï¼ˆ1=ç« ï¼Œ2=èŠ‚ï¼Œ3=å°èŠ‚ï¼‰

        Returns:
            str: æ ¼å¼åŒ–çš„æ£€ç´¢ç»“æœæ–‡æœ¬
        """
        # æ„å»º where_filter
        where_filter: Optional[Dict[str, Any]] = None
        if level_filter is not None:
            where_filter = {"level": level_filter}

        try:
            results: List[Dict[str, Any]] = retrieve_from_chromadb(
                query=query,
                collection_name=self.collection_name,
                n_results=self.n_results,
                where_filter=where_filter,
                persist_directory=self.persist_directory
            )
        except Exception as e:
            return f"âš ï¸ æ£€ç´¢å¤±è´¥: {str(e)}"

        if not results:
            return "æœªåœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚"

        # æ ¼å¼åŒ–ä¸º LLM å‹å¥½æ–‡æœ¬
        parts = []
        for i, r in enumerate(results, 1):
            part = (
                f"ã€å‚è€ƒç‰‡æ®µ {i}ã€‘\n"
                f"- æ¥æº: {r['source']}\n"
                f"- æ ‡é¢˜: {r['title']} (å±‚çº§ {r['level']})\n"
                f"- å†…å®¹: {r['content'].strip()}\n"
            )
            parts.append(part)

        return "\n".join(parts)


@CrewBase
class TeachCompeting():
    """TeachCompeting crew"""
    agents: List[BaseAgent]
    tasks: List[Task]
    agents_config = 'config/agents.yaml'
    tasks_config = 'config/tasks.yaml'

    def __init__(self):
        self._collection = None
        self._search_tool = None

    qwen_max = LLM(
        model="dashscope/qwen-max",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        temperature=0.6,
    )

    qwen3_max =LLM(
        model="dashscope/qwen3-max",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        api_key=os.getenv("DASHSCOPE_API_KEY"),
        temperature=0.6,
    )
    # Learn more about YAML configuration files here:
    # Agents: https://docs.crewai.com/concepts/agents#yaml-configuration-recommended
    # Tasks: https://docs.crewai.com/concepts/tasks#yaml-configuration-recommended
    
    # If you would like to add tools to your agents, you can learn more about it here:
    # https://docs.crewai.com/concepts/agents#agent-tools
    @property
    def collection(self):
        if self._collection is None:
            self._collection = ingest_pdfs_to_chromadb(
                pdf_dir="./arxiv_PDF",  # ç›¸å¯¹äºè¿è¡Œç›®å½•
                collection_name="ai_research"
            )
        return self._collection

    @property
    def search_tool(self):
        if self._search_tool is None:
            self._search_tool = ChromaDBSearchTool()
        return self._search_tool

    @agent
    def searcher(self) -> Agent:
        return Agent(
            config=self.agents_config['searcher'], # type: ignore[index]
            verbose=True,
            llm=self.qwen_max,
            tools=[self.search_tool]
        )

    @agent
    def idea_thinker(self) -> Agent:
        return Agent(
            config=self.agents_config['idea_thinker'],  # type: ignore[index]
            verbose=True,
            llm=self.qwen_max
        )

    @agent
    def writer1(self) -> Agent:
        return Agent(
            config=self.agents_config['writer1'], # type: ignore[index]
            verbose=True,
            llm=self.qwen_max,
        )

    @agent
    def writer2(self) -> Agent:
        return Agent(
            config=self.agents_config['writer2'],  # type: ignore[index]
            verbose=True,
            llm=self.qwen3_max,
        )

    @agent
    def polisher(self) -> Agent:
        return Agent(
            config=self.agents_config['polisher'],  # type: ignore[index]
            verbose=True,
            llm=self.qwen3_max,
        )
    # To learn more about structured task outputs,
    # task dependencies, and task callbacks, check out the documentation:
    # https://docs.crewai.com/concepts/tasks#overview-of-a-task
    @task
    def searcher_task(self) -> Task:
        return Task(
            config=self.tasks_config['searcher'], # type: ignore[index]
            agent=self.searcher()
        )

    @task
    def idea_thinker_task(self) -> Task:
        return Task(
            config=self.tasks_config['idea_thinker'],  # type: ignore[index]
            agent=self.idea_thinker(),
        )

    @task
    def writer1_task(self) -> Task:
        return Task(
            config=self.tasks_config['writer1'], # type: ignore[index]
            agent=self.writer1(),
            human_input=True
        )

    @task
    def writer2_task(self) -> Task:
        return Task(
            config=self.tasks_config['writer2'],  # type: ignore[index]
            output_file='article1.md',
            agent=self.writer2(),
            context=[self.writer1_task(), self.searcher_task(), self.idea_thinker_task()]
        )

    @task
    def polisher_task(self) -> Task:
        return Task(
            config=self.tasks_config['polisher'],  # type: ignore[index]
            output_file='article2.md',
            agent=self.polisher()
        )

    @crew
    def crew(self) -> Crew:
        """Creates the TeachCompeting crew"""
        # To learn how to add knowledge sources to your crew, check out the documentation:
        # https://docs.crewai.com/concepts/knowledge#what-is-knowledge

        return Crew(
            agents=self.agents, # Automatically created by the @agent decorator
            tasks=self.tasks, # Automatically created by the @task decorator
            process=Process.sequential,
            verbose=True,
            # process=Process.hierarchical, # In case you wanna use that instead https://docs.crewai.com/how-to/Hierarchical/
        )
